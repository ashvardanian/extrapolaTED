{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Arxiv Texts\n",
    "\n",
    "Takes abstracts (in TSV) and pre-computed E5 vectors of Arxiv papers from the HuggingFace portal, repackaging them into Parquet files, and building the USearch index. The outputs are:\n",
    "\n",
    "- `./data/ann-arxiv-2m/title_abstract.parquet`\n",
    "- `./data/ann-arxiv-2m/abstract.e5-base-v2.usearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from usearch.io import load_matrix\n",
    "from usearch.index import Index\n",
    "from encode import vectorize_e5, vectorize_uform\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors():\n",
    "    vectors = load_matrix(\"./data/ann-arxiv-2m/abstract.e5-base-v2.fbin\")\n",
    "    return vectors\n",
    "vectors = load_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = \"./data/ann-arxiv-2m/abstract.e5-base-v2.usearch\"\n",
    "index = Index(dtype=\"f16\", metric=\"cos\", ndim=768)\n",
    "\n",
    "if os.path.exists(index_path):\n",
    "    index.load(index_path)\n",
    "else:\n",
    "    batch_size = 1000  # Adjust this based on your preference\n",
    "    total_batches = int(np.ceil(vectors.shape[0] / batch_size))\n",
    "\n",
    "    # Using tqdm for progress bar\n",
    "    for i in tqdm(range(total_batches), desc=\"Indexing batches\"):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, vectors.shape[0])\n",
    "\n",
    "        batch_keys = np.arange(start_idx, end_idx)\n",
    "        batch_vectors = vectors[start_idx:end_idx]\n",
    "\n",
    "        index.add(batch_keys, batch_vectors)\n",
    "\n",
    "    index.save(index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.hardware_acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_path = \"./data/ann-arxiv-2m/title_abstract.tsv\"\n",
    "abstracts = pd.read_csv(abstracts_path, sep=\"\\t\")\n",
    "abstracts.to_parquet(\"data/ann-arxiv-2m/abstracts.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_abstract = abstracts[\"abstract\"][2]\n",
    "vectorize_e5(sample_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_e5(sample_abstract).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = index.search(vectorize_e5(sample_abstract), 10)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert matches.keys[0] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
